{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec291c8c",
   "metadata": {},
   "source": [
    "libraries used ...\n",
    "\n",
    "TRANSFORMERS-> Gives Use All AI Models T5 , BART,Pegasus, GPT-2\n",
    "\n",
    "DATASETS ‚Üí To load and prepare text data ,This helps to load large datasets like:Lecture transcripts,Text files,Summarization datasets (CNN/DailyMail)\n",
    "Without datasets, we can't preprocess or train on any dataset efficiently.\n",
    "\n",
    "SENTENCEPIECE ‚Üí Tokenizer backend for T5/Pegasus...Models like T5 and Pegasus require SentencePiece tokenization.\n",
    "Without sentencepiece, the tokenizer for these models will break.\n",
    "\n",
    "ACCELERATE ‚Üí To speed up training and use GPU..This library makes training:Faster , Easier , Automatically uses GPU if available\n",
    "Without accelerate, finetuning models becomes slow and complex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21670850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Syedh\\anaconda3\\envs\\summarizer\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Syedh\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\__init__.py:82: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 2.3.4)\n",
      "  import scipy.linalg  # noqa\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "#T5Tokenizer converts text ‚Üí numbers (tokens)\n",
    "#This is the actual T5 model used for tasks like: Summarization, Translation ,Question ,Answering\n",
    "#This is a configuration object that tells the Trainer HOW to train your model...To control, learning rate ,,batch size\n",
    "\n",
    "from datasets import Dataset\n",
    "#Dataset is a class from the HuggingFace datasets library.\n",
    "#hugging face provides the tool kit to build and train the ML models\n",
    "#It represents a clean, efficient, memory-optimized table of data used for machine learning.\n",
    "\n",
    "import torch\n",
    "#torch is the main Python library of PyTorch, which is a deep learning framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a49472b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "12.1\n",
      "True\n",
      "NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "##torch.cuda.is_available() is a PyTorch function that tells you whether your computer has a GPU that PyTorch can use.\n",
    "\n",
    "print(torch.__version__)  \n",
    "print(torch.version.cuda) \n",
    "print(torch.cuda.is_available()) \n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55732b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"lecture\": [\n",
    "\n",
    "        # Machine Learning\n",
    "        \"\"\"So, uhh... welcome üòÖ to today's class, 12:08:11. Today we're talking about Machine Learning, okay?\n",
    "        ML is, aaah, basically a part of AI that lets computers *learn* from data.\n",
    "        We have supervised... unsupervised... and umm reinforcement learning.\n",
    "        Supervised uses labeled daaata, unsupervised finds hidden patterns without labels, sooo yeah.\n",
    "        RL works on rewards + penalties ü§ñ.\n",
    "        We'll also talk about accuracy, precision, recall, F1‚Äì‚Äì score, etc.\n",
    "        Applications? Spam detection, fraud detection, cars that drive themselves üöóüí® and so on.\n",
    "        Clean data is important... like VERY important.\n",
    "        Also preprocessing: removing missing values, scaling, normalization.. blah blah.\n",
    "        Future trends: deep learning, Generative AI, LLMs üòé.\"\"\",\n",
    "\n",
    "        # DBMS\n",
    "        \"\"\"Alright sooo 09:14:55 today‚Äôs topic is Database Management Systems (DBMS)...\n",
    "        aaah okay so DBMS helps in storing + retrieving data efficiently.\n",
    "        We have three levels: physical, logical and external‚Äì‚Äì yeah remember that.\n",
    "        Relational databases, primary keys, foreign keys... normalization (1NF, 2NF, 3NF) etc.\n",
    "        Also indexing! Transaction management!\n",
    "        ACID properties ‚Üí Atomicity, Consistency, Isolation, Durability (umm very important) üëç.\n",
    "        Concurrency control... locks... timestamps... sooo users don‚Äôt mess each other up.\n",
    "        SQL vs NoSQL differences, you know.\n",
    "        Applications: banking üè¶, ecommerce, warehouses, etc.\"\"\",\n",
    "\n",
    "        # Operating Systems\n",
    "        \"\"\"Okay sooo, 10:03:07, today's lecture is on Operating Systems (OS).\n",
    "        OS acts as, umm... a bridge between user + hardware.\n",
    "        Responsibilities: process mgmt, memory mgmt, file mgmt, device control‚Ä¶ all that stuff.\n",
    "        SJF, FCFS, Priority, Round Robin scheduling‚Äì‚Äì remember these algorithms.\n",
    "        Memory? Paging + segmentation.\n",
    "        Deadlocks happen when processes wait forever üò≠.\n",
    "        Prevention, detection, avoidance... security features (auth, access control, encryption).\n",
    "        Examples: Windows, MacOS, Linux üêß.\"\"\",\n",
    "\n",
    "        #Neural Networks\n",
    "        \"\"\"Sooo 14:41:22 today's topic: Neural Networks ü§Ø.\n",
    "        Perceptrons, activation functions (ReLU, sigmoid, tanh), feed-forward networks.\n",
    "        Backpropagation updates weights using gradient desc, basically.\n",
    "        Issues like overfitting, underfitting, dropout, regularization‚Äì‚Äì aaahhhh lots of terms üòÇ.\n",
    "        Applications: images, speech, NLP, etc.\n",
    "        Deep models need huge data + GPUs sooo yeah get ready üíÄ.\"\"\",\n",
    "\n",
    "        #  Cloud Computing\n",
    "        \"\"\"Okay, quick lecture 11:55:10 on Cloud Computing ‚òÅÔ∏è.\n",
    "        Cloud = on-demand servers, storage, apps on internet, like AWS, GCP, Azure etc.\n",
    "        Service models: IaaS, PaaS, SaaS (remember pls).\n",
    "        Deployments: public, private, hybrid, community.\n",
    "        Characteristics: scalability, elasticity, pay-as-you-go sooo $$$ saved.\n",
    "        Virtualization + containers (Docker, Kubernetes üê≥).\n",
    "        Security challenges like data breaches üò¨, identity mgmt, compliance issues.\n",
    "        Used in streaming apps, e-commerce, enterprise IT.\"\"\",\n",
    "\n",
    "        # Data Science\n",
    "        \"\"\"Umm‚Ä¶ so 08:20:03 today's lecture is Data Science ü§ì.\n",
    "        Data science mixes statistics, programming, domain knowledge...\n",
    "        Steps: data collection ‚Üí cleaning ‚Üí exploration ‚Üí visualization ‚Üí modeling ‚Üí deployment.\n",
    "        Tools: Python, R, Pandas, NumPy, Matplotlib.\n",
    "        ML techniques like regression, clustering, classification.\n",
    "        Importance of feature engineering!!\n",
    "        Metrics: RMSE, R¬≤, precision, recall.\n",
    "        Applications: health, finance, marketing.\n",
    "        okay that‚Äôs it üòÇ.\"\"\",\n",
    "\n",
    "        # Computer Architecture\n",
    "        \"\"\"Sooo okay 16:18:40 today's Computer Architecture lecture.\n",
    "        It defines how hardware + software interact to run instructions.\n",
    "        It has ISA, microarchitecture, system architecture.\n",
    "        ISA ‚Üí instructions, registers, addressing modes.\n",
    "        RISC (ARM, RISC-V) vs CISC (x86).\n",
    "        Microarchitecture = ALU, control unit, caching, pipeline, branch prediction, superscalar stuff.\n",
    "        Kinda complicated ü§¶‚Äç‚ôÇÔ∏è but important.\"\"\",\n",
    "\n",
    "        # Internet of Things (IoT)\n",
    "        \"\"\"Aaah okay so IoT, 12:33:19‚Ä¶\n",
    "        IoT = devices connected through internet sending/receiving data automatically.\n",
    "        Sensors + connectivity + cloud + smart software = real-time decisions.\n",
    "        Applications: smart homes, smart cities, healthcare, farming, transport, industries.\n",
    "        Examples: thermostats, wearables, smart cameras, driverless cars üöóü§ñ, irrigation systems.\n",
    "        IoT improves automation & efficiency sooo yeah.\"\"\",\n",
    "\n",
    "        #Computer Networks\n",
    "        \"\"\"So today at 09:02:55 we discussed Computer Networks.\n",
    "        Network = devices connected to share data + resources.\n",
    "        Types: LAN, MAN, WAN, PAN.\n",
    "        Internet = largest WAN ever üåê.\n",
    "        Uses TCP/IP, HTTP, FTP protocols.\n",
    "        Components: routers, switches, servers, clients, etc.\n",
    "        Applications: communication, file sharing, cloud, business, education‚Ä¶ sooo everything.\"\"\",\n",
    "\n",
    "        # Cybersecurity\n",
    "        \"\"\"Umm okay last lecture 15:29:14 on Cybersecurity üîê.\n",
    "        Cybersecurity protects systems from attacks, malware, exploits etc.\n",
    "        Concepts: encryption, hashing, firewalls, antivirus, intrusion detection, authentication.\n",
    "        Threats: phishing üò≠, ransomware, DDoS, password attacks, MITM attacks.\n",
    "        CIA triad ‚Üí Confidentiality, Integrity, Availability.\n",
    "        Best practices: strong passwords, MFA, updates, backups, network monitoring.\n",
    "        Cybersecurity is super important today sooo be careful online üëÄ.\"\"\"\n",
    "    ],\n",
    "\n",
    "    \"summary\": [\n",
    "\n",
    "        \"This lecture explains machine learning types, evaluation metrics, preprocessing, and applications such as fraud detection and autonomous systems.\",\n",
    "\n",
    "        \"This lecture covers DBMS architecture, normalization, indexing, ACID properties, and differences between SQL and NoSQL databases.\",\n",
    "\n",
    "        \"This lecture explains OS responsibilities, scheduling algorithms, memory management, deadlocks, and common operating systems.\",\n",
    "\n",
    "        \"This lecture discusses neural networks, activation functions, backpropagation, overfitting solutions, and deep learning applications.\",\n",
    "\n",
    "        \"This lecture introduces cloud models, deployments, virtualization, containerization, and cloud security challenges.\",\n",
    "\n",
    "        \"This lecture outlines the data science pipeline, tools, ML techniques, and evaluation metrics.\",\n",
    "\n",
    "        \"This lecture explains computer architecture layers, ISA, RISC vs CISC, and microarchitecture components.\",\n",
    "\n",
    "        \"This lecture introduces IoT devices, architecture, applications, and benefits such as automation.\",\n",
    "\n",
    "        \"This lecture explains computer networks, types, protocols, devices, and real-world applications.\",\n",
    "\n",
    "        \"This lecture covers cybersecurity concepts, CIA triad, attack types, best practices, and security mechanisms.\"\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ec28d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Preprocessing\n",
    "\n",
    "import re #(Regular Expressions)is a powerful pattern matching langugage ,used\n",
    "#for search,find and manipulate text\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "\n",
    "#removing the time stamp\n",
    "\n",
    "    text=re.sub(r'\\b\\d{1,2}:\\d{2}(?::\\d{2})?\\b',\" \",text)\n",
    "# Finding thr filler words\n",
    "    filler_words = [\n",
    "        r\"\\buh+\\b\", r\"\\bum+\\b\", r\"\\bokay\\b\", r\"\\bso+\\b\", r\"\\byou know\\b\"\n",
    "    ]\n",
    "\n",
    "    #deleting the filler words\n",
    "    for fw in filler_words:\n",
    "        text = re.sub(fw, \"\", text, flags=re.IGNORECASE)\n",
    "\n",
    "#removing the emojs,symbols ,\n",
    "    text = re.sub(r\"[^a-zA-Z0-9.,!?;:\\s]\", \" \", text)\n",
    "\n",
    "#converts the text into the lower case\n",
    "    text = text.lower()\n",
    "\n",
    "#remove the extra space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1220c24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today we are going to discuss deep learning... deep learning is a subset of ml!\n"
     ]
    }
   ],
   "source": [
    "sample=sample = \"\"\"\n",
    "00:01 Sooo today we are uh going to discuss Deep Learning...\n",
    "00:05 Uhhhh deep learning is you know a subset of ML!\n",
    "\"\"\"\n",
    "\n",
    "print(clean_text(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89c77378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lectures files saved\n",
      "So, uhh... welcome üòÖ to today's class, 12:08:11. Today we're talking about Machine Learning, okay?\n",
      "        ML is, aaah, basically a part of AI that lets computers *learn* from data.\n",
      "        We have supervised... unsupervised... and umm reinforcement learning.\n",
      "        Supervised uses labeled daaata, unsupervised finds hidden patterns without labels, sooo yeah.\n",
      "        RL works on rewards + penalties ü§ñ.\n",
      "        We'll also talk about accuracy, precision, recall, F1‚Äì‚Äì score, etc.\n",
      "        Applications? Spam detection, fraud detection, cars that drive themselves üöóüí® and so on.\n",
      "        Clean data is important... like VERY important.\n",
      "        Also preprocessing: removing missing values, scaling, normalization.. blah blah.\n",
      "        Future trends: deep learning, Generative AI, LLMs üòé.\n"
     ]
    }
   ],
   "source": [
    "#saving the lectures\n",
    "\n",
    "import os\n",
    "os.makedirs(\"content/lectures\", exist_ok=True)#make a folder  (in clob content is the n main working directory)\n",
    "\n",
    "for i ,text in enumerate(data[\"lecture\"],start=1):\n",
    "  #enumerate() fuction give index number{i} and the value{text}\n",
    "#create the file path\n",
    "  file_path =f\"content/lectures/lecture_{i}.txt\"\n",
    "  #write into the file\n",
    "  with open (file_path,\"w\", encoding=\"utf-8\")as f:#encoding=\"utf-8\" ensures all charaters present\n",
    "    f.write(text)\n",
    "\n",
    "print(\"lectures files saved\")\n",
    "path = \"content/lectures\"\n",
    "\n",
    "#sorting files numerically ,in side the /content/lectures ,with Rule {KEY}\n",
    "files = sorted(\n",
    "    os.listdir(path), key=lambda x: int(x.split(\"_\") #split at _ {\"lecture\",\"2.txt\"}\n",
    "       #take the numeric part of it of indix [1]\n",
    "    [1].split(\".\")[0]) #then split that thing at \".\" and take index [0]\n",
    "    )  #convert that string into the integer\n",
    "files\n",
    "with open (f\"content/lectures/lecture_{1}.txt\",\"r\") as f:\n",
    "  print(f.read())\n",
    "\n",
    "\n",
    "\n",
    "#os.listdir(\"/content/lectures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffb5fef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', ... welcome to today s class, . today we re talking about machine learning, ? ml is, aaah, basically a part of ai that lets computers learn from data. we have supervised... unsupervised... and reinforcement learning. supervised uses labeled daaata, unsupervised finds hidden patterns without labels, yeah. rl works on rewards penalties . we ll also talk about accuracy, precision, recall, f1 score, etc. applications? spam detection, fraud detection, cars that drive themselves and on. clean data is important... like very important. also preprocessing: removing missing values, scaling, normalization.. blah blah. future trends: deep learning, generative ai, llms .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#saving the clean lectures\n",
    "\n",
    "import glob #helps python to find .txt or .jpg fies\n",
    "cleaned_texts= []\n",
    "\n",
    "for file in glob.glob(\"content/lectures/*.txt\"): #finf all {.txt} files and open them\n",
    "  with open(file, \"r\", encoding= \"utf-8\") as f:\n",
    "    raw = f.read()\n",
    "    cleaned = clean_text(raw) #we  clean the raw content with predefined regex functiom{clean_text}\n",
    "    cleaned_texts.append(cleaned) #add the clean content in cleaned_texts\n",
    "\n",
    "#new folder for clean files\n",
    "os.makedirs(\"content/cleaned/\",exist_ok=True)\n",
    "\n",
    "for i ,text in enumerate(cleaned_texts):\n",
    "  with open(f\"content/cleaned/lecture_{i}.txt\",\"w\") as f:\n",
    "    f.write(text)\n",
    "clean_path = \"content/cleaned\"\n",
    "#sort the files\n",
    "cleaned_text= sorted(\n",
    "    os.listdir(clean_path), key=lambda x: int(x.split(\"_\")\n",
    "    [1].split(\".\")[0]))\n",
    "#cleaned_text\n",
    "\n",
    "cleaned_texts[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45999afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary files saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['summary_1.txt',\n",
       " 'summary_2.txt',\n",
       " 'summary_3.txt',\n",
       " 'summary_4.txt',\n",
       " 'summary_5.txt',\n",
       " 'summary_6.txt',\n",
       " 'summary_7.txt',\n",
       " 'summary_8.txt',\n",
       " 'summary_9.txt',\n",
       " 'summary_10.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the folder for the summarys\n",
    "os.makedirs(\"content/summarys/\",exist_ok=True)\n",
    "for i ,text in enumerate(data[\"summary\"],start=1):\n",
    "  file_path =f\"content/summarys/summary_{i}.txt\"\n",
    "  with open (file_path,\"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(str(text))\n",
    "\n",
    "print(\"summary files saved\")\n",
    "\n",
    "#sorting\n",
    "summary=sorted(\n",
    "    os.listdir(\"content/summarys\"),key=lambda X: int(X.split(\"_\")\n",
    "    [1].split(\".\")[0]))\n",
    "summary\n",
    "#os.listdir(\"content/summarys\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a254d313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " {'text': 'last lecture on cybersecurity . cybersecurity protects systems from attacks, malware, exploits etc. concepts: encryption, hashing, firewalls, antivirus, intrusion detection, authentication. threats: phishing , ransomware, ddos, password attacks, mitm attacks. cia triad confidentiality, integrity, availability. best practices: strong passwords, mfa, updates, backups, network monitoring. cybersecurity is super important today be careful online .',\n",
       "  'summary': 'This lecture covers cybersecurity concepts, CIA triad, attack types, best practices, and security mechanisms.'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bulid the list of the Lecture and summery pair,If the pairing is wrong, then the model will learn incorrect mappings.\n",
    "\n",
    "import glob\n",
    "\n",
    "lectures= sorted(glob.glob(\"content/cleaned/*.txt\"))#load all leacture files\n",
    "summaries= sorted(glob.glob(\"content/summarys/*.txt\"))#load all summary files\n",
    "\n",
    "data=[] #store final data set\n",
    "\n",
    "for lec_files, sum_files in zip(lectures, summaries):#zip() joins two lists side-by-side\n",
    "\n",
    "  with open (lec_files, \"r\",encoding = \"utf-8\" )as f: #opens the lecture file,reads all text ,and saves it to lecture_text\n",
    "    lecture_text= f.read()\n",
    "\n",
    "  with open(sum_files,\"r\", encoding=\"utf-8\") as f: #opens the summary file.reads the all text,and saves it to the summsries_text\n",
    "    summary_text = f.read()\n",
    "\n",
    "\n",
    "  data.append({\"text\":lecture_text,\"summary\":summary_text}) #creates the paired entry(in the form of dictionaries)\n",
    "\n",
    "\n",
    "len(data), data[1] ##how many pairs and first pair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bed828f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'summary'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=Dataset.from_list(data) \n",
    "#coverts the data into a hugging face DataSet.\n",
    "#the data must be a LIST__Where each element is a dictionary ,and all dicitionaries have the same key\n",
    "dataset\n",
    "\n",
    "\n",
    "\n",
    "#.from_list() =list of dictionaries  --- each dictonary is equal to one row ---keys ==columns \n",
    "#   \n",
    "\n",
    "#.from_dict() =each list is equal to one column ___---All lists must be same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "373a90f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'summary'],\n",
       "        num_rows: 8\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'summary'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset= dataset.train_test_split(test_size= 0.2)#spliting the data set\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6691eb34",
   "metadata": {},
   "source": [
    "*TOCKENIZE THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bb9b5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 147.72 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 81.08 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 8\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer #from transformers labiary ,we import the T5tocknzer class\n",
    "\n",
    "tockenizer=T5Tokenizer.from_pretrained(\"t5-small\") # [from_pretrained]This is a method (function inside a class),It loads a pretrained\n",
    "                                                     # tokenizer model[t5_small] from HuggingFace\n",
    "                                                     #our lectures and summerys must be tockenized\n",
    "\n",
    "\n",
    "\n",
    "#/preprocessing or tokenizing each batch\n",
    "#So before training the model, we must:\n",
    "#1:-Convert lecture text ‚Üí token IDs\n",
    "#2:-Convert summary ‚Üí token IDs\n",
    "#3:-Put them in the correct format the model expects\n",
    "#This conversion process is cald preprocessing.\n",
    "\n",
    "\n",
    "def preprocess(batch): #batch is the group of multiple samples\n",
    "  #Tokenize the lecture text\n",
    "  model_inputs=tockenizer(batch['text'], #covert the text[batch] into Token IDs\n",
    "                          max_length=512,#Keep the maximum size =512 tockens/words,Not  long text\n",
    "                          truncation=True) #cut if the text is longer than 512\n",
    "\n",
    "  labels=tockenizer(batch[\"summary\"], #covert the summary[batch] into the Token IDs\n",
    "                  \n",
    "                    max_length=150,#with maximun size ,150 tockens , GPT2-small has max_lenght 1024\n",
    "                    truncation=True) #cut if too long\n",
    "\n",
    "                    #{Labels (summary tokens) are used only for:loss calculation (teacher forcing)}\n",
    "                    \n",
    "\n",
    " #model_inputs is result dict created for tokinizing the TEXT BATCH ,\n",
    "\n",
    "                                             #model_inputs = {\n",
    "                                                              #\"input_ids\": [...],       (tokens for lecture text)\n",
    "                                                               # \"attention_mask\": [...] (tells model what to consider as a TOKEN_ID)\n",
    "                                                              #}\n",
    "\n",
    "                                               #For example First Batch has 5 lectures texts , with 300,453,290,500,302 of TOCKEN ID lenght,\n",
    "\n",
    "                                               #A transformer requires all sequences in a batch to have the SAME length \n",
    "\n",
    "                                               #because GPUs compute things in matrix form (equal-sized rows).\n",
    "\n",
    "                                               #So to make the lenght same,we need PADDING ,adding extra zeros to make all sequences equal length.\n",
    "\n",
    "                                               #WHICH means ,300 lecture Tocken IDs will be 512 ,by adding the 212 zeros ,for padding to keep the lenght same(512),\n",
    "\n",
    "                                               #And same goes for other lectures (other tocken ID lenghts)\n",
    "\n",
    "                                               #For model must not pay attention to the padding, So for That (Tokenizer) Creates an [attention_mask](if 1 then consider tocken)\n",
    "                                               #if 0 then ignore \n",
    "\n",
    "                                               #Padding makes the sequences same length.\n",
    "\n",
    "                                               #Attention mask tells the model which part is real and which part is padding.\n",
    "\n",
    "                                               #Together they allow batching.\n",
    "#adds summary as a label\n",
    "  model_inputs[\"labels\"]= labels[\"input_ids\"] #It adds the summary tokens to the dictionary that the model will receive.\n",
    "                                              #         {\n",
    "                                               #           \"input_ids\": [...],         (lecture tokens)\n",
    "                                               #           \"attention_mask\": [...],\n",
    "                                              #             \"labels\": [...]             (summary tokens)\n",
    "                                                #         }\n",
    "\n",
    "                                                #During training:\n",
    "\n",
    "                                                #The model reads: lecture tokens\n",
    "\n",
    "                                                #The model tries to generate: summary tokens\n",
    "\n",
    "                                               #It compares its output with: labels\n",
    "\n",
    "                                              #Then calculates LOSS\n",
    "\n",
    "                                              #Then improves weights\n",
    "                                              \n",
    "                                              #When we train a model:\n",
    "                                              #input_ids ‚Üí the lecture text (what the model reads)\n",
    "                                              #labels[\"input_ids\"] ‚Üí the summary (the correct output the model should produce)\n",
    "\n",
    "\n",
    "\n",
    "  return model_inputs\n",
    "#apply the function to entire dataset\n",
    "tockenised_dataset =dataset.map(preprocess, batched=True)#HuggingFace Dataset.map() applies this preprocess() function to the entire dataset automatically, \n",
    "                                                          #batch by batch.\n",
    "\n",
    "tockenised_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1cb18e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 420.20 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 134.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tockenised_dataset.save_to_disk(\"content/tokenized_lectures\")\n",
    "#save the tokenized dataset\n",
    "\n",
    "#allof this is saved in Arrow format (efficient binary files)\n",
    "\n",
    "#hugging face creates this folder\n",
    "\n",
    "#[dataset_info.json] contains the meta data, of the dataset\n",
    "\n",
    "#[state.json]store the processing state of the dataset,that .map() was applied\n",
    "\n",
    "#This helps Hugging Face: avoid recomputing things   --know dataset history\n",
    "\n",
    "#().arrow) files come from Apache Arrow.\n",
    "#Apache Arrow is: a columnar binary data format---extremely fast---memory-efficient---perfect for ML workloads\n",
    "\n",
    "#[\n",
    "#DAtA SAVED\n",
    "\n",
    "#shards are the chunk of dataset in large data\n",
    "#(1/1 shards) ---- dataset is small, so it‚Äôs saved as one single file (not split into multiple pieces).\n",
    "#532.40 examples/s--- finished instantly, at a speed of ~532 rows per second.]\n",
    "\n",
    "\n",
    "\n",
    "#T5 automatically creates the correct attention mask for decoder labels internally.\n",
    "#T5 is an Encoder-Decorder MOdel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c53f34",
   "metadata": {},
   "source": [
    "FineTuneTheT5-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc64887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Fine-tuning T5-small means retraining a pre-trained T5-small model on our own dataset\n",
    "# so it becomes good at a specific NLP task.\n",
    "\n",
    "#loading the MODEL and THE TOKENIZER\n",
    "\n",
    " \n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "model_name=\"t5-small\"\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "model =T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7ead9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SET MODEL TO GPU\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)  \n",
    "#here it shows the entire structure of your T5ForConditionalGeneration model.‚Äù\n",
    "#T5 is an Encoder‚ÄìDecoder Transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba37cd6a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc3014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 420.20 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 134.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tockenised_dataset.save_to_disk(\"content/tokenized_lectures\")\n",
    "#save the tokenized dataset\n",
    "\n",
    "#allof this is saved in Arrow format (efficient binary files)\n",
    "\n",
    "#hugging face creates this folder\n",
    "\n",
    "#[dataset_info.json] contains the meta data, of the dataset\n",
    "\n",
    "#[state.json]store the processing state of the dataset,that .map() was applied\n",
    "\n",
    "#This helps Hugging Face: avoid recomputing things   --know dataset history\n",
    "\n",
    "#().arrow) files come from Apache Arrow.\n",
    "#Apache Arrow is: a columnar binary data format---extremely fast---memory-efficient---perfect for ML workloads\n",
    "\n",
    "#[\n",
    "#DAtA SAVED\n",
    "\n",
    "#shards are the chunk of dataset in large data\n",
    "#(1/1 shards) ---- dataset is small, so it‚Äôs saved as one single file (not split into multiple pieces).\n",
    "#532.40 examples/s--- finished instantly, at a speed of ~532 rows per second.]\n",
    "\n",
    "\n",
    "\n",
    "#T5 automatically creates the correct attention mask for decoder labels internally.\n",
    "#T5 is an Encoder-Decorder MOdel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab1caea",
   "metadata": {},
   "source": [
    "UPDATE THE PRE PROCESSING FOR THE T5 FORMAT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d25bbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPDATE THE PRE PROCESSING FOR THE T5 FORMAT  \n",
    "\n",
    "def preprocess(batch):\n",
    "\n",
    "    inputs =[\"summarize: \" + text for text in batch[\"text\"]]\n",
    "\n",
    "    #here batch is the group of the multiple samples/texts/examples\n",
    "\n",
    "    #it takes each text in the batch and prepends \"summaries: \" to it\n",
    "\n",
    "    #Because T5 is a text-to-text model, it needs a task-specific prefix to understand what task to perform.\n",
    "\n",
    "    #For smmarization, the prefix is \"summarize;\"\n",
    "\n",
    "#inputs is a list of strings, one per example in the batch\n",
    "\n",
    "#[\n",
    " # \"summarize: Deep learning is a subset of AI...\",\n",
    " # \"summarize: Neural networks are inspired by the brain...\"\n",
    "#]         \n",
    "#This is what the encoder will read/\n",
    "    \n",
    "    model_inputs = tockenizer( #tokenizer() converts text into numbers.\n",
    "        \n",
    "        inputs,# This list of strings ----> pass to the tokenizer\n",
    "\n",
    "        max_length = 512,#max length of the input sequence\n",
    "\n",
    "        truncation=True,#cut if longer than 512 tockens\n",
    "\n",
    "        padding=\"max_length\" #pad to make all sequences in the batch the same length(512)\n",
    "    )  #then it craetes the attention mask automatically.\n",
    "\n",
    "                    #{\n",
    "                         #\"input_ids\": [\n",
    "                         #   [21603, 10, 1296, 1789, ..., 0, 0],\n",
    "                          #  [21603, 10, 5421, 3921, ..., 0, 0]\n",
    "                         #],\n",
    "\n",
    "                        #\"attention_mask\": [\n",
    "                            #    [1, 1, 1, 1, ..., 0, 0],\n",
    "                             #   [1, 1, 1, 1, ..., 0, 0]\n",
    "                            #]\n",
    "                      #}\n",
    "\n",
    "\n",
    "                      #from here ,input_ids will go to T5 encoder\n",
    "\n",
    "                      #attention_mask  will go encoder self attention layers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():#‚ÄúThe text about to tokenize is for the DECODER, not the encoder.‚Äù\n",
    "\n",
    "        labels = tockenizer(    #token IDs for the decoder output.\n",
    "  \n",
    "            batch[\"summary\"], #this is the target text (summary) to be tockenized\n",
    "\n",
    "            max_length=150,\n",
    "\n",
    "            truncation=True,\n",
    "\n",
    "            padding=\"max_length\"\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        model_inputs[\"labels\"] =labels[\"input_ids\"]\n",
    "\n",
    "        return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6253efc",
   "metadata": {},
   "source": [
    "TRAINING ARGUMENTS \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77f126ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments #Training arguments is a configuration class from hugging face trasnformers libarary\n",
    "                                           #it allows us to specify various hyperparameters and settings for training our model using the Trainer API\n",
    "                                           \n",
    "\n",
    "training_args =TrainingArguments(  #setup the training arguments/settings/how to train the model,\n",
    "\n",
    "\n",
    "    output_dir=\"./lecture_summarizer\", #where to save the model checkpoints ,logs ,evaluation  #prevent loss of progress,.\n",
    "\n",
    "                                       #for example ,after every few steps of training ,the model's current state is saved to this directory so we can resume later if needed\n",
    "                                       #logs are known as the training metrics like loss,accuracy etc.\n",
    "\n",
    "    eval_strategy=\"steps\", # evaluation is done after every fixed number of training steps \n",
    "                             #evaluation helps monitor model performance on unseen data during training\n",
    "                                #so we can catch overfitting and underfitting early and adjust hyperparameters accordingly\n",
    "\n",
    "\n",
    "    per_device_train_batch_size=1,#Each GPU processes 1 example at a time, As T5 is memory intensive\n",
    "                                     #Total_examples / batch_size    =(if total examples =10 ,batch_size=1 ,that means 10 steps per epoch\n",
    "                                      #An epoch is a single complete pass through the entire training dataset\n",
    "                                     #after 10 examples ,1 epoch is completed \n",
    "                                     #after that ,next epoch starts again from example 1 to 10 ,with new updateed weights\n",
    "\n",
    "    per_device_eval_batch_size=1, #Each GPU processees 1 example at a time during evalution\n",
    "\n",
    "    gradient_accumulation_steps=3, #With batch size 1 and 10 examples, gradient_accumulation_steps=4 means the model processes \n",
    "                              # examples one by one, accumulates gradients from 4 examples, [10/4=3]\n",
    "                             # updates the weights once, and repeats this, resulting in 3 weight updates in one epoch.\n",
    "\n",
    "    learning_rate=2e-5,#Learning rate is a number that controls how much the model changes its weights after each update.\n",
    "                          #new_weight = old_weight ‚àí learning_rate √ó gradient\n",
    "\n",
    "                          #as we are fine-tuning,not training from scratch ,, as T5-small already knows language structure\n",
    "                             #so small learning rate avoids big weight chamges that could disrupt pre_treined knowledge\n",
    "\n",
    "                             #a common choice for fine-tuning transformer models is between (1e-5 to 5e-5)\n",
    "\n",
    "\n",
    "    num_train_epochs=6,#number of times the model will see the entire training dataset during tarining.\n",
    "                         #with 10 examples ,with 3 updates per epoch (due to gradient_accumulation_steps=4)\n",
    "                         #so in 6 epochs,the model will perform 18 weight updates (6 x 3 =18)\n",
    "\n",
    "    logging_steps=1,#Print training loss after every training step (weight update)\n",
    "                    #as i have 18 wight updates ,but we only get 12, because last batch of each epoch has only 2 examples ,Hence some\n",
    "                    # version of hugging face TRAINER ignore logging for incomplete batches,that is y we get 12 logs instead of 18\n",
    "\n",
    "    eval_steps=1,#means the model computes validation loss after every weight update, \n",
    "                 #so you can monitor performance continuously during training.\n",
    "                 #validation loss means how well the model is doing on unseen data\n",
    "\n",
    "    save_steps=2,#save a checkpoint of the model after every 2 weight updates\n",
    "\n",
    "    save_total_limit=2,#keep only the 2 most recent model checkpooints, to save disk space\n",
    "    \n",
    "    fp16=True,#use mixed precision training with 16-bit flaoting point numnbers,which speed up training and reduced the memory usage\n",
    "                 #In deep learning, precision means:  How many digits a number can store and how accurately it represents values.\n",
    "                 # Computers store numbers in binary (0s and 1s).       \n",
    "\n",
    "    report_to=\"none\" #diable default loggings to hugging face hub\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c27457",
   "metadata": {},
   "source": [
    "TRAINER SETup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd35e427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Syedh\\AppData\\Local\\Temp\\ipykernel_22944\\3989085227.py:8: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer= Trainer(  # this creates a trainer instance that knows how to tarin the model,\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer #Trainer is a high-level API from hugging face transformers libarary\n",
    "                                 #it handles the training loop, evaluation,saving checkpponts,backpropagation etc\n",
    "\n",
    "                                 #with Trainer ,we just need to provide the model , dataset ,and tarining arguments\n",
    "                                 # without Trainer, we would have to write our own training loop from scratch,which is complex and error-prone\n",
    "                                 # training loop = the code that runs through the dataset multiple times to train the model  \n",
    "                                                  \n",
    "trainer= Trainer(  # this creates a trainer instance that knows how to tarin the model,\n",
    "    \n",
    "\n",
    "    model=model, #the T5 model [T5ForConditionslGenration] we want to fine tune /train\n",
    "\n",
    "    args =training_args,#the tarining arguments we defined earlier\n",
    "\n",
    "    train_dataset=tockenised_dataset[\"train\"],  #the tockenized training data set\n",
    "\n",
    "\n",
    "    eval_dataset=tockenised_dataset[\"test\"],#the tockenized evaluation data set\n",
    "\n",
    "    tokenizer=tockenizer, #the tockenizer  used to process the text\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246059ac",
   "metadata": {},
   "source": [
    "START TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05a86aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:23, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.007000</td>\n",
       "      <td>4.009964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.108400</td>\n",
       "      <td>4.009964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.873900</td>\n",
       "      <td>4.009964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.956100</td>\n",
       "      <td>3.969882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.236900</td>\n",
       "      <td>3.939794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.081700</td>\n",
       "      <td>3.939794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.761700</td>\n",
       "      <td>3.911529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.249300</td>\n",
       "      <td>3.887691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.299200</td>\n",
       "      <td>3.843544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.921700</td>\n",
       "      <td>3.798261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.338800</td>\n",
       "      <td>3.772292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.309500</td>\n",
       "      <td>3.753588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.887100</td>\n",
       "      <td>3.739444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4.230000</td>\n",
       "      <td>3.724646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.287700</td>\n",
       "      <td>3.724646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.661200</td>\n",
       "      <td>3.712082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>4.012700</td>\n",
       "      <td>3.701880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3.527300</td>\n",
       "      <td>3.694170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18, training_loss=3.9305648803710938, metrics={'train_runtime': 24.4338, 'train_samples_per_second': 1.964, 'train_steps_per_second': 0.737, 'total_flos': 1419502878720.0, 'train_loss': 3.9305648803710938, 'epoch': 6.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()  #this starts the training process according to the specified training argumnets\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "#BELOW IS THE ----training log from Hugging Face Trainer.\n",
    "\n",
    "#[12/12 00:33, Epoch 6/6]   === 12 /12 means there are total 12 weight updates in 6 epochs\n",
    "                              #Each epoch has 2 weight updates (due to gradient_accumulation_steps=4 with batch size 1 and 10 examples)\n",
    "                             #00.33 is time taken so far for training\n",
    "                             #Epoch 6/6 means we are in the 6th epoch out of the total 6 epeochs.s\n",
    "\n",
    "\n",
    "\n",
    "#Training loss ---How wrong the model is on the training data it is currently learning from.\n",
    "\n",
    "\n",
    "#validation loss ---how wrong the model is on unseen data it has nevr seen before.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                             #validation loss decreases from 4.1234 to 3.9123 ,indicating the model is learning and improving on unseen data\n",
    "\n",
    "                             #traing loss decreses ,shows the model is learning from the training data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d79426c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('content/lecture_summarizer_model\\\\tokenizer_config.json',\n",
       " 'content/lecture_summarizer_model\\\\special_tokens_map.json',\n",
       " 'content/lecture_summarizer_model\\\\spiece.model',\n",
       " 'content/lecture_summarizer_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"content/lecture_summarizer_model\") #saves the file of the fine tuned model to the specified directory\n",
    "\n",
    "\n",
    "tokenizer.save_pretrained(\"content/lecture_summarizer_model\") #saves the tockenizer to the specified directory "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb999316",
   "metadata": {},
   "source": [
    "TEST THE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e56dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration \n",
    "import torch #import torch library for tensor computations and GPU support \n",
    "\n",
    "model_path = \"/content/lecture_summarizer_model\" #path where the fine tuned model is saved\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path) #lload the tokenizer from the saved moedl path\n",
    "\n",
    "model= T5ForConditionalGeneration.from_pretrained(model_path) #load the fine tuned model from the saved model pah \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" #set device to GPU if available ,else cpu\n",
    "\n",
    "model.to(device)#moves model to selected device(Gpu or Cpu)\n",
    "\n",
    "model.eval() #sets the model to evalution mode, disanling dropout and other training-specific layers\n",
    "\n",
    "\n",
    "\n",
    "#This output represents the internal architecture of the fine-tuned T5 model. \n",
    "# Although the structure remains the same as the base model, \n",
    "# the weights have been updated through fine-tuning on lecture transcripts.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa927e",
   "metadata": {},
   "source": [
    "WRITE A PREDICTION FUNCTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bec8bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(text, max_length=150): #function to genrate the summary from the lecture text\n",
    "\n",
    "\n",
    "    input_text= \"summarize: \" + text #it prepends \"summarize\" to the input text\n",
    "\n",
    "    inputs = tockenizer( #\n",
    "\n",
    "        input_text, \n",
    "\n",
    "        return_tensors=\"pt\",#inidcates that the output should be pytorch tensors\n",
    "\n",
    "        max_length=512,\n",
    "\n",
    "        truncation=True\n",
    "\n",
    "    ).to(device) #.to(device) moves the input tensors to the same device as the model(Gpu or Cpu)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    summary_ids = model.generate( #.generate() method genrates the summary token IDs from the input token IDs.\n",
    "\n",
    "\n",
    "        inputs[\"input_ids\"], #iinput IDs from the tokenixed text\n",
    "\n",
    "        max_length=120,\n",
    "\n",
    "        min_length=40, \n",
    "\n",
    "        num_beams=6, #beam is a search strategy that keeps track of the top N most likely sequences at each step.\n",
    "                    #steps= each word generated by the model in the summary \n",
    "                    #num_beams =6 means the model considers the top 6 most likely next words at each step when generating the summary.\n",
    "                    #this allows the model to explore multiple possible summaries simultaneously,improving the chances of finding a high-quality output\n",
    "                    # more beams = better quality but slower generation\n",
    "                     \n",
    "        no_repeat_ngram_size=3,#prevents the model from repeating any sequence of 3 words in the genrated summary.\n",
    "                                 #this helps avoid redundancy and makes the summary more coherent\n",
    "                                 #for example if the model has already generated \"the cat sat\",it won't generate \"the cat sat\" again later in the summary \n",
    "                                 #this improves the readability of the summary\n",
    "                                \n",
    "        repetition_penalty=2.5, #discourages the model from repeating the same words or phrases excessively\n",
    "                                #a higher value means more penalty for repetition\n",
    "                                #this helps produce more diverse  and intresting summaries\n",
    "                            \n",
    "\n",
    "                                   \n",
    "        length_penalty=1.8, #this means the model is encouraged to genrate longer summaries\n",
    "                            #a value >1.0 favors longer outputs, while <1.0 favors shorter ones.\n",
    "                            #penalty here means the model is rewarded for genrating longer summaries\n",
    "\n",
    "        early_stopping=True #stops the generation process once the model is confident it has produced a complete summary.\n",
    "                        \n",
    "\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    return tockenizer.decode(summary_ids[0], skip_special_tokens=True) #decodes the generated token IDs back into human-readable text,\n",
    "                                                                        #skipping special tokens like <s>,which mean start of sequence,\n",
    "                                                                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffabb9e4",
   "metadata": {},
   "source": [
    "TEST WITH A NEW LECTURE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb6cedf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY:\n",
      " AI agents can be reactive, responding instantly to inputs, or proactive, planning future actions based on predicted outcomes. in multi-agent systems, several AI agents interact with each other, collaborating or competing to solve large-scale problems.\n"
     ]
    }
   ],
   "source": [
    "test_lecture =\"\"\"\n",
    "AI Agents are intelligent software systems designed to perceive their environment, make decisions, and take actions to achieve specific goals with minimal human intervention. Unlike traditional programs that follow fixed rules, AI agents can learn from data, adapt to changing conditions, and improve their performance over time. They often combine techniques from machine learning, natural language processing, computer vision, and reinforcement learning to operate effectively in complex environments.\n",
    "AI agents can be reactive, responding instantly to inputs, or proactive, planning future actions based on predicted outcomes. Examples include virtual assistants like chatbots, recommendation systems on streaming platforms, autonomous robots, and self-driving vehicles. In multi-agent systems, several AI agents interact with each other, collaborating or competing to solve large-scale problems such as traffic management, financial trading, or online gaming.\n",
    "One of the key strengths of AI agents is their ability to automate repetitive and time-consuming tasks, increasing efficiency and reducing human error. In healthcare, AI agents assist in diagnosis and patient monitoring; in education, they personalize learning experiences; and in business, they optimize supply chains and customer support.\n",
    "However, the development of AI agents also raises ethical and social concerns, including data privacy, transparency, and accountability. Ensuring that AI agents are reliable, fair, and aligned with human values is essential. As technology advances, AI agents are expected to play an increasingly important role in shaping the future of intelligent systems and everyday life.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "summary = generate_summary(test_lecture)\n",
    "\n",
    "print(\"SUMMARY:\\n\",summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5734525",
   "metadata": {},
   "source": [
    "GENRATE THE SUMMARY FOR THE TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7e82a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.55s/it]\n"
     ]
    }
   ],
   "source": [
    "#Your evaluation loop ran successfully--- model generated summaries---Inference is working correctly\n",
    "#If  test set had 10 samples, it would show:10/10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_data = tockenised_dataset[\"test\"] #move the tockenized test dataset to test_data variable\n",
    "                                       #this dataset will be used to evaluate the model's performance after fine-tuning\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm #tqdm stands for \"taqadhum\" in arabic means \"progress\"\n",
    "                           #it is a python library that adds a progress bar to loops\n",
    "                           #it helps visualize the progress of long-running operatins\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "generated_summaries = [] #list to store the generated summaries\n",
    "\n",
    "\n",
    "reference_summaries = [] #list to store the reference (true) summaries from thr dataset\n",
    "                    \n",
    "\n",
    "\n",
    "model.eval() # sets the model to evaluation mode, disabling dropout and other training-specific layers\n",
    "               #dropout is a regularization technique used during training to prevent overfitting\n",
    "               #dropout means randomly turning off some neurons during training\n",
    "\n",
    "\n",
    "for example in tqdm(test_data): #iterate over each example in the test dataset with a progress bar\n",
    "\n",
    "\n",
    "    input_ids = torch.tensor(example[\"input_ids\"]).unsqueeze(0).to(device) #converts the input IDS to a pytorch tensor\n",
    "                                                                   #unsequeeze(0) means adding a batch dimension at the start\n",
    "\n",
    "    with torch.no_grad(): #disables gradient calculation,which saves memory and computation during inference \n",
    "                             #as we are not training the model here ,just generating the summaries\n",
    "\n",
    "\n",
    "        summary_ids = model.generate( \n",
    "\n",
    "\n",
    "            input_ids,\n",
    "\n",
    "\n",
    "            max_length=120,\n",
    "\n",
    "            num_beams=6,\n",
    "\n",
    "\n",
    "            no_repeat_ngram_size=3\n",
    "        )\n",
    "\n",
    "    generated = tokenizer.decode(summary_ids[0], skip_special_tokens=True) #decodes the generated tocken IDs back into human-readable text\n",
    "\n",
    "\n",
    "    reference = tokenizer.decode(example[\"labels\"], skip_special_tokens=True) #decodes the reference summary tockens IDs back into human-readable text\n",
    "                                                                     \n",
    "\n",
    "    \n",
    "\n",
    "    generated_summaries.append(generated) #adds the genrated summary to the list\n",
    "\n",
    "\n",
    "    reference_summaries.append(reference) #adds the reference summary to the list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfe300f",
   "metadata": {},
   "source": [
    "COMPUTE ROUGE SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eadbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1: 0.2456\n",
      "rouge2: 0.0516\n",
      "rougeL: 0.2130\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from rouge_score import rouge_scorer #rouge_score means Recall-oriented Understudy for Gisting Evaluation\n",
    "                                       #it is a set of meterics used to evalute the quality of generated text,such as summaries\n",
    "                                       #by comparing them to reference texts\n",
    "\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(   #RougeScorer is a class that computes ROUGE scores between two texts\n",
    "                                     #it measures the overlap of n-grams,word sequences,and word pairs between the genearated summary and the reference summary\n",
    "                                     \n",
    "\n",
    "\n",
    "    [\"rouge1\", \"rouge2\", \"rougeL\"],  #here \"rouge1\" measures unigram overlap,which means single words\n",
    "                                    #\"rouge2\" measures bigram overlap,which means two word sequences ,like \"deep learning\" which is a biagram\n",
    "                                    #\n",
    "\n",
    "\n",
    "    use_stemmer=True\n",
    ")\n",
    "\n",
    "scores = {\"rouge1\": [], \"rouge2\": [], \"rougeL\": []}\n",
    "\n",
    "for gen, ref in zip(generated_summaries, reference_summaries):\n",
    "\n",
    "    score = scorer.score(ref, gen)\n",
    "\n",
    "    for key in scores:\n",
    "\n",
    "        scores[key].append(score[key].fmeasure)\n",
    "\n",
    "for key in scores:\n",
    "    \n",
    "    print(f\"{key}: {sum(scores[key]) / len(scores[key]):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b873e776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
